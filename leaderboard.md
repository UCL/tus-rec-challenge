---
title: Leaderboard
layout: home
nav_order: 99
---
| **Rank** | **Team Name** | **Team Members**                              | **Team Affiliation**                      | **Final Score** | **Global Score** | **Local Score** | **Pixel Score** | **Landmark Score** |     **GPE (mm)**      |     **GLE (mm)**      |     **LPE (mm)**     |     **LLE (mm)**     | **Run Time (s)** |
|----------|---------------|-----------------------------------------------|-------------------------------------------|-----------------|------------------|-----------------|-----------------|--------------------|------------------|------------------|-----------------|-----------------|------------------|
|  1   |      MUSIC Lab | Mingyuan Luo, Zhongnuo Yan, Jiongquan Chen, Xin Yang, Dong Ni | Shenzhen University, China     | **0.844±0.150** | 0.756±0.263  | 0.932±0.093 | 0.870±0.143 |  0.817±0.172   | 7.139±3.585  | 6.231±3.713  | 0.099±0.014 | 0.086±0.019 | 5.423±0.677  |
|  2   | ISRU-DKFZ| Nektarios Winter, Caelan Haney, Phuc Nguyen, Lucas Steinberger | German Cancer Research Center, Heidelberg, Germany | **0.773±0.196** | 0.694±0.289  | 0.852±0.176 | 0.797±0.190 |  0.749±0.222   | 7.726±4.241  | 6.861±4.634  | 0.103±0.018 | 0.090±0.024 | 7.311±0.791  |
|  3   |           ZJR           | Yuan Zhao, Mingjie Jiang, Bowen Ren | City University of Hong Kong, Hong Kong, Hong Kong Centre for Cerebro-cardiovascular Health Engineering (COCHE), Hong Kong| **0.639±0.188** | 0.783±0.270  | 0.495±0.202 | 0.642±0.182 |  0.635±0.221   | 6.901±3.597  | 6.047±3.897  | 0.116±0.017 | 0.101±0.022 | 9.632±1.088  |
|  4   |         AMI-Lab  | SiYeoul Lee, SeonHo Kim, MinKyung Seo, MinWoo Kim | Pusan National University, South Korea        | **0.541±0.272** | 0.500±0.360  | 0.581±0.272 | 0.560±0.278 |  0.521±0.291   | 9.696±6.116  | 8.698±6.337  | 0.114±0.026 | 0.103±0.036 | 49.650±6.280 |
|  5   |         Baseline        | TUS-REC Organisation Team                     | University College London, United Kingdom | **0.098±0.147** | 0.146±0.247  | 0.051±0.108 | 0.074±0.132 |  0.122±0.177   | 12.490±5.462 | 11.129±5.838 | 0.135±0.024 | 0.118±0.031 | 8.135±0.996  |


> Note: All scores (the larger the better) are normalised using the range of scores among all teams and thus may change if new submissions are added. The raw values of DDF errors (the smaller the better) before normalisation are also listed for your reference. Note that in some cases higher score may be assgined to teams with slightly larger ddf errors. That's because they have performed uniformly better than other teams in most scans and thus will have a higher normalised score. All values are rounded to 3 decimal places.
